{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0aa78a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c6e2721",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_files_labelled = {\n",
    "    0 : \"Constituency_Name\",\n",
    "    1 : \"Candidates_Info\",\n",
    "    2 : \"Electors_Info\",\n",
    "    3 : \"Voters_Info\",\n",
    "    4 : \"Votes_Info\",\n",
    "    5 : \"Polling_Stations\",\n",
    "    6 : \"Dates\",\n",
    "    7 : \"Result\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "048423fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_drop_empty_columns(df):\n",
    "    n_df = df.copy()\n",
    "    empty_cols = [(col,empty) for col,empty in n_df.isna().all().items()]\n",
    "    for (n_col, n_empty) in empty_cols:\n",
    "        if(n_col in ['MALE', 'FEMALE', 'TOTAL']):\n",
    "            continue\n",
    "\n",
    "        if(n_empty):\n",
    "            n_df = n_df.drop(n_col, axis = 'columns')\n",
    "            \n",
    "    return n_df\n",
    "\n",
    "\n",
    "def x_drop_empty_rows(df):\n",
    "    n_df = df.copy()\n",
    "    empty_rows = n_df.isna().all(axis = 'columns')\n",
    "    n_df = n_df[~empty_rows].copy()\n",
    "    return n_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58a656a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8\n",
    "TARGET_STATE = \"Maharashtra\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a90bf433",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_YEARS = [int(i) for i in os.listdir(os.path.join('states', TARGET_STATE)) if(not i.startswith(\".\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "729e0eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1962\n",
      "1967\n",
      "1972\n",
      "1978\n",
      "1980\n",
      "1985\n",
      "1990\n",
      "1995\n",
      "1999\n",
      "2004\n",
      "2009\n",
      "2014\n"
     ]
    }
   ],
   "source": [
    "for year in sorted(ALL_YEARS):\n",
    "    print(year)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f50ccf39",
   "metadata": {},
   "source": [
    "1962 - done\n",
    "1967 - done\n",
    "1969 - \n",
    "1974 - done\n",
    "1977 - done\n",
    "1980 - done\n",
    "1985\n",
    "1989\n",
    "1991\n",
    "1993\n",
    "1996\n",
    "2002\n",
    "2007\n",
    "2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee4e4549",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_YEAR = 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a2b69f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tar_dir = os.path.join('states', 'states', TARGET_STATE, f\"{TARGET_YEAR}\", f\"tabula-{TARGET_YEAR}_constituency_summary\")\n",
    "tar_dir = os.path.join('states', TARGET_STATE, f\"{TARGET_YEAR}\", f\"tabula-{TARGET_YEAR}_ConstituencyData\")\n",
    "csv_files = [i for i in os.listdir(tar_dir) if(i.endswith(\"csv\"))]\n",
    "file_df = pd.DataFrame({\"file\" : csv_files})\n",
    "file_df['file_num'] = file_df['file'].str.split('-').str[-1].str.split(\".\").str[0].astype(\"int\")\n",
    "file_df = file_df.sort_values('file_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e3faadb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea4f0e35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IV. VOTES</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>TAR_VARIABLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. TOTAL VOTES POLLED ON EVM</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>TOTAL VOTES POLLED ON EVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. TOTAL DEDUCTED VOTES FROM EVM(TEST</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>TOTAL DEDUCTED VOTES FROM EVM VOTES+VOTES NOT ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VOTES+VOTES NOT RETRIVED+VOTES REJECTED DUE TO</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OTHER REASONS + 'NOTA')</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3. TOTALVALID VOTES POLLED ON EVM</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>TOTALVALID VOTES POLLED ON EVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4. POSTAL VOTES COUNTED</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>POSTAL VOTES COUNTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>511</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5. POSTAL VOTES DEDUCTED(REJECTED POSTAL</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>POSTAL VOTES DEDUCTED VOTES + POSTAL VOTES POL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>VOTES + POSTAL VOTES POLLED FOR 'NOTA')</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6. VALID POSTAL VOTES</td>\n",
       "      <td>502</td>\n",
       "      <td>VALID POSTAL VOTES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.TOTAL VALID VOTES POLLED</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>TOTAL VALID VOTES POLLED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8.TEST VOTES POLLED ON EVM</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>TEST VOTES POLLED ON EVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9.VOTES POLLED FOR 'NOTA' (INCLUDING POSTAL)</td>\n",
       "      <td>1362</td>\n",
       "      <td>VOTES POLLED FOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10. TENDERED VOTES</td>\n",
       "      <td>0</td>\n",
       "      <td>TENDERED VOTES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         IV. VOTES  Unnamed: 1  \\\n",
       "0                     1. TOTAL VOTES POLLED ON EVM        <NA>   \n",
       "1            2. TOTAL DEDUCTED VOTES FROM EVM(TEST        <NA>   \n",
       "2   VOTES+VOTES NOT RETRIVED+VOTES REJECTED DUE TO        <NA>   \n",
       "3                          OTHER REASONS + 'NOTA')        <NA>   \n",
       "4                3. TOTALVALID VOTES POLLED ON EVM        <NA>   \n",
       "5                          4. POSTAL VOTES COUNTED        <NA>   \n",
       "6                                              NaN         511   \n",
       "7         5. POSTAL VOTES DEDUCTED(REJECTED POSTAL        <NA>   \n",
       "8          VOTES + POSTAL VOTES POLLED FOR 'NOTA')        <NA>   \n",
       "9                                              NaN           9   \n",
       "10                           6. VALID POSTAL VOTES         502   \n",
       "11                      7.TOTAL VALID VOTES POLLED        <NA>   \n",
       "12                      8.TEST VOTES POLLED ON EVM        <NA>   \n",
       "13    9.VOTES POLLED FOR 'NOTA' (INCLUDING POSTAL)        1362   \n",
       "14                              10. TENDERED VOTES           0   \n",
       "\n",
       "                                         TAR_VARIABLE  \n",
       "0                           TOTAL VOTES POLLED ON EVM  \n",
       "1   TOTAL DEDUCTED VOTES FROM EVM VOTES+VOTES NOT ...  \n",
       "2                                                 NaN  \n",
       "3                                                 NaN  \n",
       "4                      TOTALVALID VOTES POLLED ON EVM  \n",
       "5                                POSTAL VOTES COUNTED  \n",
       "6                                                 NaN  \n",
       "7   POSTAL VOTES DEDUCTED VOTES + POSTAL VOTES POL...  \n",
       "8                                                 NaN  \n",
       "9                                                 NaN  \n",
       "10                                 VALID POSTAL VOTES  \n",
       "11                           TOTAL VALID VOTES POLLED  \n",
       "12                           TEST VOTES POLLED ON EVM  \n",
       "13                                  VOTES POLLED FOR   \n",
       "14                                     TENDERED VOTES  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tabula-2014_ConstituencyData-1808.csv', 'tabula-2014_ConstituencyData-1809.csv', 'tabula-2014_ConstituencyData-1810.csv', 'tabula-2014_ConstituencyData-1811.csv', 'tabula-2014_ConstituencyData-1812.csv', 'tabula-2014_ConstituencyData-1813.csv', 'tabula-2014_ConstituencyData-1814.csv', 'tabula-2014_ConstituencyData-1815.csv']\n",
      "[511, 9, 502, 1362, 0]\n",
      "['TOTAL VOTES POLLED ON EVM', \"TOTAL DEDUCTED VOTES FROM EVM VOTES+VOTES NOT RETRIVED+VOTES REJECTED DUE TO OTHER REASONS + 'NOTA')\", 'TOTALVALID VOTES POLLED ON EVM', 'POSTAL VOTES COUNTED', \"POSTAL VOTES DEDUCTED VOTES + POSTAL VOTES POLLED FOR 'NOTA')\", 'VALID POSTAL VOTES', 'TOTAL VALID VOTES POLLED', 'TEST VOTES POLLED ON EVM', 'VOTES POLLED FOR ', 'TENDERED VOTES']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;28mprint\u001b[39m(tmp_variable_values)\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;28mprint\u001b[39m(tmp_variable_names)\n\u001b[0;32m--> 215\u001b[0m     n_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVALUE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmp_variable_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTAR_VARIABLE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmp_variable_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvariable_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmp_variable_names\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m zero_rows \u001b[38;5;241m=\u001b[39m (n_df \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mall(axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m&\u001b[39m (n_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTAR_VARIABLE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    222\u001b[0m n_df \u001b[38;5;241m=\u001b[39m n_df\u001b[38;5;241m.\u001b[39mdrop(zero_rows[zero_rows]\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/frame.py:663\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    657\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    658\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    659\u001b[0m     )\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    662\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 663\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/internals/construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/internals/construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/internals/construction.py:666\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    664\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    670\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    671\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "constituency_wise_data = {}\n",
    "completeness_ratios = {}\n",
    "\n",
    "for i in range(0, len(csv_files), block_size):\n",
    "    tar_files = file_df['file'].to_list()[i : i+block_size]\n",
    "    tmp_dfs = {idx : os.path.join(tar_dir, file) for idx,file in enumerate(tar_files)}\n",
    "    \n",
    "    const_found = False\n",
    "    current_constituency = 0\n",
    "    \n",
    "    # Men, Women, Others\n",
    "    n_genders = 2\n",
    "    uncontested = False\n",
    "    \n",
    "    for idx, df_path in tmp_dfs.items():\n",
    "        header_match = {\n",
    "            7 : [0,1],\n",
    "            5 : None\n",
    "        }\n",
    "        header = header_match.get(idx, [0])\n",
    "        df = pd.read_csv(df_path, header = header)\n",
    "        if(idx == 5):\n",
    "            # drop first row\n",
    "            df = df.iloc[1:, :]\n",
    "        \n",
    "        if(idx == 0):\n",
    "            tar_val = ' '.join(df.columns)\n",
    "            tar_obj = re.match(\".+ (\\d+)\\s*-\\s*([A-Za-z ]+)\", tar_val)\n",
    "            if(tar_obj):\n",
    "                const_found = True\n",
    "                const_num = int(tar_obj[1])\n",
    "                current_constituency = const_num\n",
    "                constituency_wise_data[const_num] = {}\n",
    "                constituency_wise_data[current_constituency]['Constituency_Name'] = tar_obj[2]\n",
    "                completeness_ratios[current_constituency] = {}\n",
    "                \n",
    "            else:\n",
    "                print(tar_files)\n",
    "                display(df)\n",
    "                raise ValueError(\"Could not extract constituency number\")\n",
    "                \n",
    "                \n",
    "            \n",
    "        else:\n",
    "            n_df = df.copy()\n",
    "            \n",
    "            if(idx == 4 and uncontested):\n",
    "                n_df['VALUE'] = -1\n",
    "            \n",
    "            # Polling Dates\n",
    "            if(idx == 6):\n",
    "                n_df.columns = n_df.iloc[0]\n",
    "                n_df = n_df.drop([0], axis = 'index')\n",
    "                n_df.columns = n_df.columns.fillna(\"k\")\n",
    "                \n",
    "            # idx1,2,3 have some partially empty first cols... let's merge these and drop the extras\n",
    "            if(idx == 1):\n",
    "                tar_cols = [i for i in n_df.columns if(i.startswith(\"Unnamed\"))]\n",
    "                if(len(tar_cols) > 1):\n",
    "                    keep_col = tar_cols[0]\n",
    "                    n_df[keep_col] = n_df[tar_cols].fillna(\"\").agg(lambda x: ' '.join(x), axis = 'columns')\n",
    "                    n_df = n_df.drop(tar_cols[1:], axis = 'columns')\n",
    "                \n",
    "            # Drop empty columns, if any\n",
    "            n_df = x_drop_empty_columns(n_df)\n",
    "                    \n",
    "            \n",
    "            \n",
    "            \n",
    "            # Now parse the blocks separately...\n",
    "            # Note that block 0 has already been parsed\n",
    "            \n",
    "            # Block 5,6,7\n",
    "            if(idx in [5, 6, 7]):\n",
    "                # Polling Stations\n",
    "                if(idx == 5):\n",
    "                    \n",
    "                    # Find row that has a regex match first\n",
    "                    info_found = False\n",
    "                    found_obj = None\n",
    "                    for b_idx, b_row in n_df.iterrows():\n",
    "                        tar_row =  ' '.join([str(i) for i in b_row.dropna()])\n",
    "                        tar_obj = re.match(\"[A-Z]+\\s*:?\\s*(\\d+)? [A-Z ]+:?\\s*(\\d+)\", tar_row)\n",
    "                        if(tar_obj):\n",
    "                            info_found = True\n",
    "                            found_obj = tar_obj\n",
    "                            break\n",
    "\n",
    "                    if(info_found):\n",
    "                        num_stations = found_obj[1]\n",
    "                        avg_electors = found_obj[2]\n",
    "                        \n",
    "                    else:\n",
    "                        num_stations = -1\n",
    "                        avg_electors = -1\n",
    "                        \n",
    "                    constituency_wise_data[const_num]['Polling_Stations'] = {\n",
    "                        \"Number\" : num_stations,\n",
    "                        \"Average_Electors_per_Station\" : avg_electors,\n",
    "                        \"regex_Match\" : info_found\n",
    "                    }\n",
    "                \n",
    "                # Dates\n",
    "                elif(idx == 6):\n",
    "                    if(uncontested or n_df.empty):\n",
    "                        n_df = pd.DataFrame({\"POLLING\" : -1}, index = [1])\n",
    "                    \n",
    "                    n_df.columns = [f\"DATE_{i}\" for i in n_df.columns]\n",
    "                    n_df = x_drop_empty_rows(n_df)\n",
    "                    n_df = n_df.reset_index(drop = True)\n",
    "                    constituency_wise_data[const_num].update({\n",
    "                        \"Dates\" : n_df.T.to_dict()[0]\n",
    "                    })\n",
    "\n",
    "                    \n",
    "                \n",
    "                # Candidates Info\n",
    "                elif(idx == 7):\n",
    "                    n_df = x_drop_empty_rows(n_df)\n",
    "                    \n",
    "                    # Manually deal with uncontested\n",
    "                    if(uncontested):\n",
    "                        # Multi-indexed column\n",
    "                        n_df.columns = [i[1] for i in n_df.columns]\n",
    "                        pick_rows = ['PARTY', 'CANDIDATE', 'VOTES']\n",
    "                        n_df = n_df[pick_rows]\n",
    "                        n_df = n_df.dropna(how = 'any')\n",
    "                        n_df['POSITION'] = 'WINNER'\n",
    "                        n_df['VOTES'] = -1\n",
    "                        if(n_df['CANDIDATE'].str.contains('UNCONTESTED').any()):\n",
    "                            n_df['CANDIDATE'] = n_df['CANDIDATE'].str.replace(\"UNCONTESTED\", \"\")\n",
    "                            n_df['CANDIDATE'] = n_df['CANDIDATE'].str.removesuffix(\"(\").str.strip()\n",
    "                    \n",
    "                    else:\n",
    "                        n_df.columns = ['POSITION', 'PARTY', 'CANDIDATE', 'VOTES']\n",
    "                        n_df['POSITION'] = n_df['POSITION'].str.removesuffix(\":\").str.strip().str.upper().str.replace(\" \", \"-\")\n",
    "                    \n",
    "                    na_values_count = n_df.isna().sum().sum()\n",
    "                    total_values = n_df.shape[0] * n_df.shape[1]\n",
    "                    completeness_ratios[current_constituency]['Result'] = {\n",
    "                        \"Total_Cells\" : total_values,\n",
    "                        \"NA_Cells\" : na_values_count,\n",
    "                        \"NA_Proportion\" : (na_values_count / total_values) * 100\n",
    "                    }\n",
    "                    \n",
    "                    # Multi-line names - merge with previous line\n",
    "                    if(len(n_df) > 2):\n",
    "                        print(\"[FOUND] Multi-line name problem... Fixing with iterative row merge\")\n",
    "                        display(n_df)\n",
    "                        for row_idx, row_vals in n_df.iterrows():\n",
    "                            if(row_vals.isna().any()):\n",
    "                                na_cols = ~row_vals.isna()\n",
    "                                for k,v in na_cols.items():\n",
    "                                    if(v):\n",
    "                                        n_df.loc[row_idx - 1, k] += \" \" + str(n_df.loc[row_idx, k])\n",
    "\n",
    "                                n_df = n_df.drop(row_idx, axis = 'index')\n",
    "                            \n",
    "\n",
    "                    constituency_wise_data[const_num]['Result'] = n_df.set_index('POSITION').T.to_dict()\n",
    "\n",
    "            else:\n",
    "                variable_name = n_df.columns[0]\n",
    "                for col in n_df.columns:\n",
    "                    if(col == variable_name):\n",
    "                        continue\n",
    "                        \n",
    "                    if(not uncontested and (idx == 3)):\n",
    "                        if(\"Unnamed: 1\" in n_df.columns):\n",
    "                            z_vals = n_df['Unnamed: 1'].dropna().values\n",
    "                            if(len(z_vals) == 1 and z_vals[0].lower().strip() == \"uncontested\"):\n",
    "                                uncontested = True\n",
    "                                n_df['Unnamed: 1'] = -1\n",
    "                                n_df['FEMALE'] = -1\n",
    "                                if(n_genders == 3):\n",
    "                                    n_df['Others'] = -1\n",
    "                                n_df['TOTAL'] = -1\n",
    "                    \n",
    "                    constituency_wise_data[current_constituency]['Uncontested'] = uncontested            \n",
    "                                \n",
    "                        \n",
    "                    n_df[col] = n_df[col].astype(\"Int64\")\n",
    "                    \n",
    "                \n",
    "                n_df['TAR_VARIABLE'] = n_df[variable_name].str.extract(\"\\d+\\.\\s*([A-Z ]+)\")\n",
    "                if(idx == 4):\n",
    "                    # Iteratively merge the rows\n",
    "                    last_good_row = None\n",
    "                    \n",
    "                    for gz_idx, gz_row in n_df.iterrows():\n",
    "                        if(not pd.isna(gz_row['TAR_VARIABLE'])):\n",
    "                            last_good_row = gz_idx\n",
    "                        \n",
    "                        if(pd.isna(gz_row['TAR_VARIABLE']) and not pd.isna(gz_row[variable_name])):\n",
    "                            \n",
    "                            n_df.loc[last_good_row, 'TAR_VARIABLE'] += \" \" + gz_row[variable_name]\n",
    "                            \n",
    "                    # after merging, create a new df with the correct variable names & values\n",
    "                    tmp_variable_names = n_df['TAR_VARIABLE'].dropna().to_list()\n",
    "                    tar_variable_values_column = [i for i in n_df.columns if(i not in ['TAR_VARIABLE', variable_name])]\n",
    "                    \n",
    "                    # unable to pick the VALUE column...\n",
    "                    if(len(tar_variable_values_column) > 1):\n",
    "                        raise ValueError(\"could not find values column!\")\n",
    "                        \n",
    "                    tar_variable_values_column = tar_variable_values_column[0]\n",
    "                    tmp_variable_values = n_df[tar_variable_values_column].dropna().to_list()\n",
    "                    \n",
    "                    # keep variable name column only because it is kept for other dfs as well, will drop later...\n",
    "                    if(len(tmp_variable_values) != len(tmp_variable_names)):\n",
    "                        display(n_df)\n",
    "                        print(tar_files)\n",
    "                        print(tmp_variable_values)\n",
    "                        print(tmp_variable_names)\n",
    "                    n_df = pd.DataFrame({\n",
    "                        'VALUE' : tmp_variable_values,\n",
    "                        'TAR_VARIABLE' : tmp_variable_names,\n",
    "                        variable_name : tmp_variable_names\n",
    "                    })\n",
    "\n",
    "                zero_rows = (n_df == 0).all(axis = 'columns') & (n_df['TAR_VARIABLE'] == 0)\n",
    "                n_df = n_df.drop(zero_rows[zero_rows].index)\n",
    "                \n",
    "                \n",
    "                n_df = n_df.drop(variable_name, axis = 'columns')\n",
    "                \n",
    "                # Code to shift variables\n",
    "                for z_idx, z_row in n_df.iterrows():\n",
    "                    if(z_row.isna().any()):\n",
    "                        other_keys = [i for i in z_row.keys() if(i != \"TAR_VARIABLE\")]\n",
    "                        keep_values = z_row[other_keys].dropna().values\n",
    "                        num_of_na = z_row[other_keys].isna().sum()\n",
    "                        na_values = [pd.NA for i in range(num_of_na)]\n",
    "                        n_df.loc[z_idx, other_keys] = list(keep_values) + na_values\n",
    "                        \n",
    "\n",
    "                # Drop empty columns again\n",
    "                n_df = x_drop_empty_columns(n_df)\n",
    "                \n",
    "                # Drop rows that are entirely empty as well\n",
    "                n_df = x_drop_empty_rows(n_df)\n",
    "                \n",
    "                block_name = block_files_labelled[idx]\n",
    "                na_values_count = n_df.isna().sum().sum()\n",
    "                total_values = n_df.shape[0] * n_df.shape[1]\n",
    "                completeness_ratios[current_constituency][block_name] = {\n",
    "                    \"Total_Cells\" : total_values,\n",
    "                    \"NA_Cells\" : na_values_count,\n",
    "                    \"NA_Proportion\" : (na_values_count / total_values) * 100\n",
    "                }\n",
    "                    \n",
    "                n_df = n_df.fillna(0)\n",
    "                \n",
    "                # Set n_gender correctly\n",
    "                if(idx == 1):\n",
    "                    n_genders = sum([True for i in n_df.columns if(i in ['MALE', 'MEN', 'WOMEN', 'FEMALE', 'Others', 'OTHERS', 'THIRD GENDER'])])\n",
    "                \n",
    "                \n",
    "                # Set column names correctly\n",
    "                if(idx == 4):\n",
    "                    out_columns = ['VALUE', 'TAR_VARIABLE']\n",
    "                    \n",
    "                else:\n",
    "                    out_columns = ['MEN', 'WOMEN', 'OTHERS', 'TOTAL', 'TAR_VARIABLE']\n",
    "                    if(n_genders == 2):\n",
    "                        out_columns = ['MEN', 'WOMEN', 'TOTAL', 'TAR_VARIABLE']\n",
    "                        \n",
    "                if(len(n_df.columns) != len(out_columns)):\n",
    "                    n_df.insert(loc = 1, column = 'WOMEN', value = 0)\n",
    "                    constituency_wise_data[current_constituency]['Women_Column_Forced'] = True\n",
    "                    \n",
    "                n_df.columns = out_columns\n",
    "                \n",
    "                # Keep data\n",
    "                block_name = block_files_labelled[idx]\n",
    "                \n",
    "                gz_tar_cols = n_df.set_index('TAR_VARIABLE').T.columns\n",
    "                gz_count = Counter(gz_tar_cols)\n",
    "                if(gz_count.most_common(1)[0][1] > 1):\n",
    "                    print(tar_files)\n",
    "                    display(n_df)\n",
    "                \n",
    "                constituency_wise_data[current_constituency][block_name] = n_df.set_index('TAR_VARIABLE').T.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e25fbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_df = pd.DataFrame()\n",
    "for const_num in constituency_wise_data.keys():\n",
    "    const_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Constituency_No\" : [const_num], \n",
    "             \"Uncontested\" : [constituency_wise_data[const_num]['Uncontested']],\n",
    "             \"Women_Col_Forced\" : [constituency_wise_data[const_num].get('Women_Column_Forced', False)]\n",
    "        }\n",
    "    )\n",
    "    # Dictionary^2\n",
    "    tar_keys2 = ['Dates', 'Polling_Stations']\n",
    "    for key in tar_keys2:\n",
    "        for k,v in constituency_wise_data[const_num][key].items():\n",
    "            colname = f\"{key}_{k}\"\n",
    "            const_df[colname] = v\n",
    "            \n",
    "    \n",
    "    # Dictionary^3\n",
    "    tar_keys = ['Candidates_Info', 'Result', 'Electors_Info', 'Voters_Info', 'Votes_Info']\n",
    "    for key in tar_keys:\n",
    "        for k,v in constituency_wise_data[const_num][key].items():\n",
    "            cols = {f\"{key.strip()}_{k.strip()}_{subsection}\" : value for subsection, value in v.items()}\n",
    "            x_df = pd.DataFrame(cols, index = [0])\n",
    "            const_df = pd.concat([const_df, x_df], axis = 1)\n",
    "\n",
    "        completeness_df = pd.DataFrame(completeness_ratios[const_num][key], index = [0])\n",
    "        completeness_df.columns = [f\"Completeness_{key}_{i}\" for i in completeness_df.columns]\n",
    "        const_df = pd.concat([const_df, completeness_df], axis = 1)\n",
    "            \n",
    "    state_df = pd.concat([state_df, const_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "d5ecded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = os.path.join(\"Parsed_Data\", TARGET_STATE)\n",
    "os.makedirs(outpath, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "6f423880",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_filename = f\"{TARGET_STATE}_{TARGET_YEAR}.csv\"\n",
    "state_df.to_csv(\n",
    "    os.path.join(outpath, out_filename),\n",
    "    index = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "dea908a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Constituency_No  Uncontested  Women_Col_Forced Dates_DATE_POLLING  \\\n",
      "0                1        False             False         21-02-1967   \n",
      "0                2        False             False         21-02-1967   \n",
      "0                3        False             False         21-02-1967   \n",
      "0                4        False             False         21-02-1967   \n",
      "0                5        False             False         21-02-1967   \n",
      "\n",
      "   Polling_Stations_Number  Polling_Stations_Average_Electors_per_Station  \\\n",
      "0                       -1                                             -1   \n",
      "0                       -1                                             -1   \n",
      "0                       -1                                             -1   \n",
      "0                       -1                                             -1   \n",
      "0                       -1                                             -1   \n",
      "\n",
      "   Polling_Stations_regex_Match  Candidates_Info_NOMINATED_MEN  \\\n",
      "0                         False                              0   \n",
      "0                         False                              0   \n",
      "0                         False                              0   \n",
      "0                         False                              0   \n",
      "0                         False                              0   \n",
      "\n",
      "   Candidates_Info_NOMINATED_WOMEN  Candidates_Info_NOMINATED_TOTAL  ...  \\\n",
      "0                                0                                0  ...   \n",
      "0                                0                                0  ...   \n",
      "0                                0                                0  ...   \n",
      "0                                0                                0  ...   \n",
      "0                                0                                0  ...   \n",
      "\n",
      "   Completeness_Voters_Info_NA_Cells  Completeness_Voters_Info_NA_Proportion  \\\n",
      "0                                  0                                     0.0   \n",
      "0                                  0                                     0.0   \n",
      "0                                  0                                     0.0   \n",
      "0                                  0                                     0.0   \n",
      "0                                  0                                     0.0   \n",
      "\n",
      "   Votes_Info_POLLED_VALUE  Votes_Info_VALID_VALUE  Votes_Info_REJECTED_VALUE  \\\n",
      "0                    29326                   27826                       1500   \n",
      "0                    38529                   36247                       2282   \n",
      "0                    31529                   28729                       2800   \n",
      "0                    39375                   37692                       1683   \n",
      "0                    31533                   29015                       2518   \n",
      "\n",
      "   Votes_Info_MISSING_VALUE  Votes_Info_TENDERED_VALUE  \\\n",
      "0                         0                          0   \n",
      "0                         0                          0   \n",
      "0                         0                          0   \n",
      "0                         0                          0   \n",
      "0                         0                          0   \n",
      "\n",
      "   Completeness_Votes_Info_Total_Cells  Completeness_Votes_Info_NA_Cells  \\\n",
      "0                                   10                                 0   \n",
      "0                                   10                                 0   \n",
      "0                                   10                                 0   \n",
      "0                                   10                                 0   \n",
      "0                                   10                                 0   \n",
      "\n",
      "   Completeness_Votes_Info_NA_Proportion  \n",
      "0                                    0.0  \n",
      "0                                    0.0  \n",
      "0                                    0.0  \n",
      "0                                    0.0  \n",
      "0                                    0.0  \n",
      "\n",
      "[5 rows x 66 columns]\n"
     ]
    }
   ],
   "source": [
    "print(state_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207e0d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
